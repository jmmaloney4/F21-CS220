{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "300e4135",
   "metadata": {},
   "outputs": [],
   "source": [
    "# project: p9\n",
    "# submitter: ccmaloney\n",
    "# partner: jmaloney3\n",
    "# hours: 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "985cafca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import csv\n",
    "from os import path\n",
    "\n",
    "from collections import namedtuple\n",
    "\n",
    "def process_csv(filename):\n",
    "    example_file = open(filename, encoding=\"utf-8\")\n",
    "    example_reader = csv.reader(example_file)\n",
    "    example_data = list(example_reader)\n",
    "    example_file.close()\n",
    "    return example_data\n",
    "\n",
    "sample_data_path = path.join('tweets', 'sample_data')\n",
    "full_data_path = path.join('tweets', 'full_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "10b0f1a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Q1: How many files are present in the sample_data directory?\n",
    " \n",
    "len(os.listdir(sample_data_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c42b6bb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Q2: How many files are present in the full_data directory?\n",
    "len(os.listdir(full_data_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9eb603f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sample_data/1.csv',\n",
       " 'sample_data/2.csv',\n",
       " 'sample_data/1.json',\n",
       " 'sample_data/2.json']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Q3: What are the paths of all the files in the sample_data directory?\n",
    "sample_data_paths = list(map(lambda x: path.join(\"sample_data\", x), os.listdir(path.join('tweets', 'sample_data'))))\n",
    "sample_data_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "34d0d678",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['full_data/5.csv',\n",
       " 'full_data/4.csv',\n",
       " 'full_data/1.csv',\n",
       " 'full_data/3.csv',\n",
       " 'full_data/2.csv',\n",
       " 'full_data/1.json',\n",
       " 'full_data/2.json',\n",
       " 'full_data/3.json',\n",
       " 'full_data/4.json',\n",
       " 'full_data/5.json']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Q4: What are the paths of all the files in the full_data directory?\n",
    "full_data_paths = list(map(lambda x: path.join(\"full_data\", x), os.listdir(full_data_path)))\n",
    "full_data_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fb5bd24d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sample_data/1.csv', 'sample_data/2.csv']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Q5: What are the paths of the CSV files present in the sample_data directory?\n",
    "list(filter(lambda x: x.endswith('.csv'), sample_data_paths))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1a0434b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['full_data/1.json',\n",
       " 'full_data/2.json',\n",
       " 'full_data/3.json',\n",
       " 'full_data/4.json',\n",
       " 'full_data/5.json']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Q6: What are the paths of the json files present in the full_data directory?\n",
    "list(filter(lambda x: x.endswith('.json'), full_data_paths))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9d3a98b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tweet(tweet_id='id123', username='user456', num_liked=100, length=140)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Tweet = namedtuple('Tweet',['tweet_id', 'username', 'num_liked', 'length'])\n",
    "t = Tweet(\"id123\", \"user456\", 100, 140)\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "23a8235a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Tweet(tweet_id='1467812799', username='USERID_7', num_liked=3340, length=103),\n",
       " Tweet(tweet_id='1467812964', username='USERID_10', num_liked=3684, length=93),\n",
       " Tweet(tweet_id='1467813137', username='USERID_5', num_liked=6816, length=20),\n",
       " Tweet(tweet_id='1467813579', username='USERID_1', num_liked=1348, length=64),\n",
       " Tweet(tweet_id='1467813782', username='USERID_1', num_liked=4770, length=79)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Q7: What are the tweets present in the CSV file 2.csv in sample_data?\n",
    "def fix_num(s):\n",
    "    m = 1\n",
    "    if s.endswith('K'):\n",
    "        m = 1000\n",
    "        s = s[:-1]\n",
    "    elif s.endswith('M'):\n",
    "        m = 1000000\n",
    "        s = s[:-1]\n",
    "    try: return int(s) * m\n",
    "    except ValueError: return None \n",
    "    \n",
    "def process_tweets(csv_file):\n",
    "    header = csv_file[0]\n",
    "    csv_file = csv_file[1:]\n",
    "    id_idx = header.index(\"tweet_id\")\n",
    "    user_idx = header.index(\"username\")\n",
    "    liked_idx = header.index(\"num_liked\")\n",
    "    text_idx = header.index(\"tweet_text\")\n",
    "    \n",
    "    def process_tweet(row):\n",
    "        if len(row) != len(header):\n",
    "            return None\n",
    "        return(Tweet(\n",
    "            row[id_idx], \n",
    "            row[user_idx], \n",
    "            fix_num(row[liked_idx]), \n",
    "            len(row[text_idx])))\n",
    "        \n",
    "    return list(filter(lambda x: x != None, map(process_tweet, csv_file)))\n",
    "\n",
    "samplefile2 = process_csv(path.join(sample_data_path, '2.csv'))\n",
    "process_tweets(samplefile2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "41d2a4d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Tweet(tweet_id='1467901250', username='USERID_6', num_liked=7790, length=132),\n",
       " Tweet(tweet_id='1467901346', username='USERID_1', num_liked=5079, length=137),\n",
       " Tweet(tweet_id='1467901437', username='USERID_6', num_liked=5913, length=60),\n",
       " Tweet(tweet_id='1467901500', username='USERID_7', num_liked=7376, length=13),\n",
       " Tweet(tweet_id='1467901839', username='USERID_7', num_liked=4871, length=101),\n",
       " Tweet(tweet_id='1467904302', username='USERID_8', num_liked=1195, length=91),\n",
       " Tweet(tweet_id='1467905125', username='USERID_7', num_liked=1738, length=27),\n",
       " Tweet(tweet_id='1467905378', username='USERID_2', num_liked=4420, length=111),\n",
       " Tweet(tweet_id='1467905653', username='USERID_10', num_liked=8845, length=82),\n",
       " Tweet(tweet_id='1467906151', username='USERID_8', num_liked=6711, length=45),\n",
       " Tweet(tweet_id='1467906345', username='USERID_3', num_liked=8279, length=46),\n",
       " Tweet(tweet_id='1467906723', username='USERID_6', num_liked=7222, length=28),\n",
       " Tweet(tweet_id='1467907298', username='USERID_8', num_liked=9005, length=61),\n",
       " Tweet(tweet_id='1467907751', username='USERID_2', num_liked=9048, length=110),\n",
       " Tweet(tweet_id='1467907876', username='USERID_7', num_liked=1347, length=87),\n",
       " Tweet(tweet_id='1467908012', username='USERID_1', num_liked=1809, length=50),\n",
       " Tweet(tweet_id='1467908134', username='USERID_7', num_liked=8983, length=66),\n",
       " Tweet(tweet_id='1467908456', username='USERID_5', num_liked=2265, length=138),\n",
       " Tweet(tweet_id='1467908672', username='USERID_10', num_liked=1692, length=48),\n",
       " Tweet(tweet_id='1467908798', username='USERID_2', num_liked=1659, length=51),\n",
       " Tweet(tweet_id='1467909124', username='USERID_4', num_liked=9406, length=118),\n",
       " Tweet(tweet_id='1467909222', username='USERID_5', num_liked=8887, length=136),\n",
       " Tweet(tweet_id='1467909292', username='USERID_10', num_liked=5179, length=45),\n",
       " Tweet(tweet_id='1467910531', username='USERID_7', num_liked=6172, length=34),\n",
       " Tweet(tweet_id='1467910689', username='USERID_3', num_liked=1529, length=37),\n",
       " Tweet(tweet_id='1467910932', username='USERID_8', num_liked=1507, length=68),\n",
       " Tweet(tweet_id='1467910986', username='USERID_6', num_liked=836, length=66),\n",
       " Tweet(tweet_id='1467910995', username='USERID_4', num_liked=2886, length=57),\n",
       " Tweet(tweet_id='1467911036', username='USERID_7', num_liked=6950, length=101),\n",
       " Tweet(tweet_id='1467911302', username='USERID_10', num_liked=8562, length=119),\n",
       " Tweet(tweet_id='1467911624', username='USERID_5', num_liked=5668, length=77),\n",
       " Tweet(tweet_id='1467911846', username='USERID_3', num_liked=1352, length=67),\n",
       " Tweet(tweet_id='1467912100', username='USERID_6', num_liked=3394, length=94),\n",
       " Tweet(tweet_id='1467912333', username='USERID_7', num_liked=3345, length=49),\n",
       " Tweet(tweet_id='1467912572', username='USERID_3', num_liked=36, length=80),\n",
       " Tweet(tweet_id='1467912842', username='USERID_4', num_liked=496, length=14),\n",
       " Tweet(tweet_id='1467912994', username='USERID_8', num_liked=926, length=57),\n",
       " Tweet(tweet_id='1467913111', username='USERID_7', num_liked=5185, length=144),\n",
       " Tweet(tweet_id='1467913608', username='USERID_8', num_liked=8262, length=111),\n",
       " Tweet(tweet_id='1467914434', username='USERID_1', num_liked=1269, length=49),\n",
       " Tweet(tweet_id='1467914499', username='USERID_2', num_liked=910, length=138),\n",
       " Tweet(tweet_id='1467914916', username='USERID_4', num_liked=3232, length=91),\n",
       " Tweet(tweet_id='1467915140', username='USERID_7', num_liked=1996, length=22),\n",
       " Tweet(tweet_id='1467915612', username='USERID_6', num_liked=4014, length=41),\n",
       " Tweet(tweet_id='1467915670', username='USERID_2', num_liked=5287, length=138),\n",
       " Tweet(tweet_id='1467916510', username='USERID_8', num_liked=8150, length=96),\n",
       " Tweet(tweet_id='1467916595', username='USERID_6', num_liked=1178, length=138),\n",
       " Tweet(tweet_id='1467916695', username='USERID_10', num_liked=6691, length=54),\n",
       " Tweet(tweet_id='1467916700', username='USERID_9', num_liked=2519, length=136),\n",
       " Tweet(tweet_id='1467916820', username='USERID_10', num_liked=8557, length=127)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Q8: What are the tweets present in the CSV file 3.csv in full_data?\n",
    "file3 = process_csv(path.join(full_data_path, '3.csv'))\n",
    "\n",
    "process_tweets(file3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "02d1a21c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Tweet(tweet_id='1467876711', username='USERID_10', num_liked=1117, length=84),\n",
       " Tweet(tweet_id='1467877496', username='USERID_1', num_liked=2062, length=106),\n",
       " Tweet(tweet_id='1467877833', username='USERID_2', num_liked=4270, length=89),\n",
       " Tweet(tweet_id='1467877865', username='USERID_1', num_liked=5899, length=30),\n",
       " Tweet(tweet_id='1467878057', username='USERID_6', num_liked=703, length=42),\n",
       " Tweet(tweet_id='1467878557', username='USERID_6', num_liked=5814, length=61),\n",
       " Tweet(tweet_id='1467878633', username='USERID_2', num_liked=2351, length=33),\n",
       " Tweet(tweet_id='1467878971', username='USERID_2', num_liked=2238, length=27),\n",
       " Tweet(tweet_id='1467878983', username='USERID_8', num_liked=4860, length=61),\n",
       " Tweet(tweet_id='1467879480', username='USERID_4', num_liked=1345, length=97),\n",
       " Tweet(tweet_id='1467879984', username='USERID_2', num_liked=3694, length=69),\n",
       " Tweet(tweet_id='1467880085', username='USERID_4', num_liked=2478, length=120),\n",
       " Tweet(tweet_id='1467880431', username='USERID_3', num_liked=9407, length=85),\n",
       " Tweet(tweet_id='1467880442', username='USERID_2', num_liked=5125, length=96),\n",
       " Tweet(tweet_id='1467880463', username='USERID_9', num_liked=1226, length=29),\n",
       " Tweet(tweet_id='1467880692', username='USERID_6', num_liked=4989, length=49),\n",
       " Tweet(tweet_id='1467881131', username='USERID_10', num_liked=732, length=107),\n",
       " Tweet(tweet_id='1467881373', username='USERID_6', num_liked=8615, length=145),\n",
       " Tweet(tweet_id='1467881376', username='USERID_4', num_liked=4378, length=49),\n",
       " Tweet(tweet_id='1467881457', username='USERID_7', num_liked=119, length=27),\n",
       " Tweet(tweet_id='1467881686', username='USERID_5', num_liked=8136, length=46),\n",
       " Tweet(tweet_id='1467881809', username='USERID_4', num_liked=1797, length=138),\n",
       " Tweet(tweet_id='1467881897', username='USERID_5', num_liked=2314, length=76),\n",
       " Tweet(tweet_id='1467881920', username='USERID_3', num_liked=4101, length=112),\n",
       " Tweet(tweet_id='1467882140', username='USERID_8', num_liked=5320, length=137),\n",
       " Tweet(tweet_id='1467882491', username='USERID_10', num_liked=3512, length=55),\n",
       " Tweet(tweet_id='1467882592', username='USERID_10', num_liked=1887, length=67),\n",
       " Tweet(tweet_id='1467882902', username='USERID_3', num_liked=4646, length=48),\n",
       " Tweet(tweet_id='1467888679', username='USERID_8', num_liked=3089, length=27),\n",
       " Tweet(tweet_id='1467888732', username='USERID_7', num_liked=2800, length=48),\n",
       " Tweet(tweet_id='1467888953', username='USERID_3', num_liked=3951, length=46),\n",
       " Tweet(tweet_id='1467889231', username='USERID_5', num_liked=1320, length=79),\n",
       " Tweet(tweet_id='1467889334', username='USERID_5', num_liked=8495, length=42),\n",
       " Tweet(tweet_id='1467889574', username='USERID_1', num_liked=4696, length=123),\n",
       " Tweet(tweet_id='1467889791', username='USERID_5', num_liked=4027, length=132),\n",
       " Tweet(tweet_id='1467889988', username='USERID_2', num_liked=7394, length=51),\n",
       " Tweet(tweet_id='1467890079', username='USERID_8', num_liked=2556, length=38),\n",
       " Tweet(tweet_id='1467890222', username='USERID_2', num_liked=227, length=107),\n",
       " Tweet(tweet_id='1467890723', username='USERID_1', num_liked=96, length=134),\n",
       " Tweet(tweet_id='1467891826', username='USERID_9', num_liked=2021, length=113),\n",
       " Tweet(tweet_id='1467891880', username='USERID_7', num_liked=6847, length=96),\n",
       " Tweet(tweet_id='1467892075', username='USERID_6', num_liked=2816, length=124),\n",
       " Tweet(tweet_id='1467892515', username='USERID_5', num_liked=917, length=39),\n",
       " Tweet(tweet_id='1467892667', username='USERID_2', num_liked=8270, length=20),\n",
       " Tweet(tweet_id='1467892720', username='USERID_3', num_liked=3227, length=128)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Q9: What are the tweets present in the CSV file 2.csv in full_data?\n",
    "\n",
    "file2 = process_csv(path.join(full_data_path, '2.csv'))\n",
    "\n",
    "process_tweets(file2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5eeea1a1",
   "metadata": {},
   "outputs": [
    {
     "ename": "JSONDecodeError",
     "evalue": "Expecting value: line 1 column 1 (char 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-abe270088ac7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mprocess_json_tweets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mread_json\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson_file1_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-35-abe270088ac7>\u001b[0m in \u001b[0;36mread_json\u001b[0;34m(file)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mread_json\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/json/__init__.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(fp, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    291\u001b[0m     \u001b[0mkwarg\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0motherwise\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mJSONDecoder\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mused\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m     \"\"\"\n\u001b[0;32m--> 293\u001b[0;31m     return loads(fp.read(),\n\u001b[0m\u001b[1;32m    294\u001b[0m         \u001b[0mcls\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobject_hook\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobject_hook\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m         \u001b[0mparse_float\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparse_float\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparse_int\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparse_int\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/json/__init__.py\u001b[0m in \u001b[0;36mloads\u001b[0;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    355\u001b[0m             \u001b[0mparse_int\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mparse_float\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m             parse_constant is None and object_pairs_hook is None and not kw):\n\u001b[0;32m--> 357\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_default_decoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    358\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m         \u001b[0mcls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mJSONDecoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/json/decoder.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, s, _w)\u001b[0m\n\u001b[1;32m    335\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m         \"\"\"\n\u001b[0;32m--> 337\u001b[0;31m         \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_w\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    338\u001b[0m         \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_w\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/json/decoder.py\u001b[0m in \u001b[0;36mraw_decode\u001b[0;34m(self, s, idx)\u001b[0m\n\u001b[1;32m    353\u001b[0m             \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscan_once\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 355\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mJSONDecodeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Expecting value\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    356\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mJSONDecodeError\u001b[0m: Expecting value: line 1 column 1 (char 0)"
     ]
    }
   ],
   "source": [
    "#Q10: What are the tweets present in the JSON file 1.json in sample_data?\n",
    "json_file1_path = path.join(sample_data_path, '1.json')\n",
    "def process_json_tweets(data):\n",
    "    def process_json_tweet(i, data):\n",
    "        return(Tweet(i, data['username'],data['num_liked'],len(data['tweet_text'])))\n",
    "    return list(map(lambda x: process_json_tweet(x[0], x[1]), data.items()))\n",
    "    \n",
    "def read_json(file):\n",
    "    f = open(file, encoding=\"utf-8\")\n",
    "    data = json.load(f)\n",
    "    f.close()\n",
    "    return data\n",
    "\n",
    "process_json_tweets(read_json(json_file1_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1a5e15db",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Tweet(tweet_id='1467812416', username='USERID_9', num_liked=5278, length=43),\n",
       " Tweet(tweet_id='1467812579', username='USERID_1', num_liked=9700, length=26),\n",
       " Tweet(tweet_id='1467812723', username='USERID_3', num_liked=5414, length=94),\n",
       " Tweet(tweet_id='1467812771', username='USERID_8', num_liked=2190, length=77),\n",
       " Tweet(tweet_id='1467812784', username='USERID_10', num_liked=2667, length=117)]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Q11: What are the tweets present in the JSON file 2.json in sample_data?\n",
    "json_file2_path = path.join(sample_data_path, '2.json')\n",
    "\n",
    "process_json_tweets(read_json(json_file2_path))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c8b91a27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Tweet(tweet_id='1467892760', username='USERID_6', num_liked=4443, length=56),\n",
       " Tweet(tweet_id='1467892889', username='USERID_1', num_liked=7439, length=91),\n",
       " Tweet(tweet_id='1467892945', username='USERID_4', num_liked=8101, length=43),\n",
       " Tweet(tweet_id='1467893163', username='USERID_3', num_liked=6754, length=74),\n",
       " Tweet(tweet_id='1467893258', username='USERID_7', num_liked=1415, length=74),\n",
       " Tweet(tweet_id='1467893275', username='USERID_6', num_liked=9002, length=70),\n",
       " Tweet(tweet_id='1467893504', username='USERID_9', num_liked=4940, length=25),\n",
       " Tweet(tweet_id='1467893730', username='USERID_4', num_liked=840, length=90),\n",
       " Tweet(tweet_id='1467894593', username='USERID_2', num_liked='869M', length=136),\n",
       " Tweet(tweet_id='1467894600', username='USERID_8', num_liked='915k', length=67),\n",
       " Tweet(tweet_id='1467894746', username='USERID_4', num_liked=3185, length=107),\n",
       " Tweet(tweet_id='1467894749', username='USERID_5', num_liked=6311, length=40),\n",
       " Tweet(tweet_id='1467894750', username='USERID_6', num_liked=1046, length=46),\n",
       " Tweet(tweet_id='1467894786', username='USERID_7', num_liked=4709, length=136),\n",
       " Tweet(tweet_id='1467894841', username='USERID_8', num_liked=803, length=102),\n",
       " Tweet(tweet_id='1467894898', username='USERID_7', num_liked=2692, length=76),\n",
       " Tweet(tweet_id='1467895048', username='USERID_10', num_liked=9822, length=136),\n",
       " Tweet(tweet_id='1467895109', username='USERID_7', num_liked=3255, length=133),\n",
       " Tweet(tweet_id='1467895424', username='USERID_10', num_liked=3423, length=41),\n",
       " Tweet(tweet_id='1467895478', username='USERID_8', num_liked=926, length=67),\n",
       " Tweet(tweet_id='1467895481', username='USERID_5', num_liked=6120, length=49),\n",
       " Tweet(tweet_id='1467895712', username='USERID_8', num_liked=8551, length=136),\n",
       " Tweet(tweet_id='1467896211', username='USERID_6', num_liked=3966, length=31),\n",
       " Tweet(tweet_id='1467896253', username='USERID_2', num_liked=4906, length=91),\n",
       " Tweet(tweet_id='1467896463', username='USERID_9', num_liked=1728, length=136),\n",
       " Tweet(tweet_id='1467896777', username='USERID_10', num_liked='unkown', length=92),\n",
       " Tweet(tweet_id='1467896778', username='USERID_4', num_liked=886, length=97),\n",
       " Tweet(tweet_id='1467896898', username='USERID_7', num_liked=2972, length=58),\n",
       " Tweet(tweet_id='1467896911', username='USERID_9', num_liked=5160, length=136),\n",
       " Tweet(tweet_id='1467896996', username='USERID_10', num_liked=6540, length=61),\n",
       " Tweet(tweet_id='1467897316', username='USERID_2', num_liked=7890, length=64),\n",
       " Tweet(tweet_id='1467897981', username='USERID_9', num_liked=3034, length=136),\n",
       " Tweet(tweet_id='1467898061', username='USERID_8', num_liked=9271, length=145),\n",
       " Tweet(tweet_id='1467898076', username='USERID_7', num_liked=5075, length=136),\n",
       " Tweet(tweet_id='1467898078', username='USERID_10', num_liked=9705, length=104),\n",
       " Tweet(tweet_id='1467898511', username='USERID_2', num_liked=3477, length=99),\n",
       " Tweet(tweet_id='1467898676', username='USERID_9', num_liked=6766, length=58),\n",
       " Tweet(tweet_id='1467899025', username='USERID_6', num_liked=4660, length=137),\n",
       " Tweet(tweet_id='1467899451', username='USERID_1', num_liked=1861, length=138),\n",
       " Tweet(tweet_id='1467899605', username='USERID_9', num_liked=3209, length=90),\n",
       " Tweet(tweet_id='1467899707', username='USERID_6', num_liked=1941, length=123),\n",
       " Tweet(tweet_id='1467899753', username='USERID_10', num_liked=675, length=32),\n",
       " Tweet(tweet_id='1467900033', username='USERID_10', num_liked=9041, length=36),\n",
       " Tweet(tweet_id='1467900037', username='USERID_8', num_liked=6640, length=70),\n",
       " Tweet(tweet_id='1467900244', username='USERID_10', num_liked=1618, length=45),\n",
       " Tweet(tweet_id='1467900431', username='USERID_9', num_liked=3306, length=34),\n",
       " Tweet(tweet_id='1467900545', username='USERID_7', num_liked=148, length=13),\n",
       " Tweet(tweet_id='1467900898', username='USERID_1', num_liked=1149, length=131),\n",
       " Tweet(tweet_id='1467901135', username='USERID_4', num_liked=5825, length=94),\n",
       " Tweet(tweet_id='1467901188', username='USERID_1', num_liked=8852, length=138)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Q12: What are the tweets present in the JSON file 3.json in full_data?\n",
    "full_json_file3_path = path.join(full_data_path, '3.json')\n",
    "\n",
    "process_json_tweets(read_json(full_json_file3_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fac43213",
   "metadata": {},
   "outputs": [
    {
     "ename": "JSONDecodeError",
     "evalue": "Expecting property name enclosed in double quotes: line 64 column 5 (char 2243)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-180103b7ba9c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mfull_json_file1_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfull_data_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'1.json'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mprocess_json_tweets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mread_json\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfull_json_file1_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;31m#f = open(full_json_file1_path, \"r\", encoding=\"utf-8\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m#data1 = f.read()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-26-a69e6e913de9>\u001b[0m in \u001b[0;36mread_json\u001b[0;34m(file)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/json/__init__.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(fp, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    291\u001b[0m     \u001b[0mkwarg\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0motherwise\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mJSONDecoder\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mused\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m     \"\"\"\n\u001b[0;32m--> 293\u001b[0;31m     return loads(fp.read(),\n\u001b[0m\u001b[1;32m    294\u001b[0m         \u001b[0mcls\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobject_hook\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobject_hook\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m         \u001b[0mparse_float\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparse_float\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparse_int\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparse_int\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/json/__init__.py\u001b[0m in \u001b[0;36mloads\u001b[0;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    355\u001b[0m             \u001b[0mparse_int\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mparse_float\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m             parse_constant is None and object_pairs_hook is None and not kw):\n\u001b[0;32m--> 357\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_default_decoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    358\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m         \u001b[0mcls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mJSONDecoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/json/decoder.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, s, _w)\u001b[0m\n\u001b[1;32m    335\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m         \"\"\"\n\u001b[0;32m--> 337\u001b[0;31m         \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_w\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    338\u001b[0m         \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_w\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/json/decoder.py\u001b[0m in \u001b[0;36mraw_decode\u001b[0;34m(self, s, idx)\u001b[0m\n\u001b[1;32m    351\u001b[0m         \"\"\"\n\u001b[1;32m    352\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 353\u001b[0;31m             \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscan_once\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    354\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mJSONDecodeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Expecting value\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mJSONDecodeError\u001b[0m: Expecting property name enclosed in double quotes: line 64 column 5 (char 2243)"
     ]
    }
   ],
   "source": [
    "#Q13: What are the tweets present in the JSON file 1.json in full_data?\n",
    "\n",
    "full_json_file1_path = path.join(full_data_path, '1.json')\n",
    "\n",
    "process_json_tweets(read_json(full_json_file1_path))\n",
    "#f = open(full_json_file1_path, \"r\", encoding=\"utf-8\")\n",
    "#data1 = f.read()\n",
    "#f.close()\n",
    "\n",
    "\n",
    "#data1 = json.loads()\n",
    "data1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "097c9e8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q14: Return all the tweet objects with a length greater than 140 in full_data.\n",
    "\n",
    "#Create a function whose inputs are an integer textLength, \n",
    "#and a string directory that returns a list containing all \n",
    "#the tweets with text greater than textLength in the directory. \n",
    "#It should read all the files in the directory and combine \n",
    "#the tweets into one list. Remember to deal with broken json\n",
    "#files by skipping them.\n",
    "\n",
    "def tweets_greater_than(textLength,directory):\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c16911a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q15: Return a list of all the tweet objects with a length greater than 100 in sample_data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d0d4470",
   "metadata": {},
   "outputs": [],
   "source": [
    "read_json(json_file2_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46315e3c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
